{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9563d52",
   "metadata": {},
   "source": [
    "Import the necessary procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8037e80-0e3d-4393-a4b9-7ce5eb405e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2676addb",
   "metadata": {},
   "source": [
    "Please fill the bottom 2 with the appropriate Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cac5d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir=\"../FER2013/train/\"  \n",
    "test_dir=\"../FER2013/test/\"    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0522fe73",
   "metadata": {},
   "source": [
    "Starting to use Keras to generate the shifts in the training data, using it next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1176a206",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    width_shift_range = 0.1,        \n",
    "    height_shift_range = 0.1,       \n",
    "    horizontal_flip = True,         \n",
    "    rescale = 1./255,               \n",
    "    validation_split = 0.2          # Set aside some amount of data for validation ( Removed or not Removed? TBD)\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    validation_split = 0.2\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ee725c-9d9f-42fe-b7de-03d013ad8af7",
   "metadata": {},
   "source": [
    "Moving on to calling the appropriate functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8cdfb2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22968 images belonging to 7 classes.\n",
      "Found 5741 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory = train_dir,           \n",
    "    target_size = (48, 48),          \n",
    "    batch_size = 64,                 \n",
    "    color_mode = \"grayscale\",        \n",
    "    class_mode = \"categorical\",      \n",
    "    subset = \"training\"              \n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory = train_dir,            \n",
    "    target_size = (48, 48),          \n",
    "    batch_size = 64,                 \n",
    "    color_mode = \"grayscale\",        \n",
    "    class_mode = \"categorical\",      \n",
    "    subset = \"validation\"            \n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=(48, 48),\n",
    "    batch_size=64,\n",
    "    color_mode=\"grayscale\", \n",
    "    class_mode=\"categorical\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f0df4e-4955-4e26-b59c-09f08c451232",
   "metadata": {},
   "source": [
    "Saving the data modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "696dfb95-0a1e-4b2a-b536-b94fd139c359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "def extract_data(generator):\n",
    "    X, y = [], []\n",
    "    for _ in range(generator.samples // generator.batch_size + 1):\n",
    "        batch = next(generator)\n",
    "        X.append(batch[0])\n",
    "        y.append(batch[1])\n",
    "    return np.concatenate(X), np.concatenate(y)\n",
    "\n",
    "# Extract data from generators\n",
    "X_train, y_train = extract_data(train_generator)\n",
    "X_val, y_val = extract_data(validation_generator)\n",
    "X_test, y_test = extract_data(test_generator)\n",
    "\n",
    "# Save datasets as .npy files\n",
    "\n",
    "np.save(\"../refined_data/X_train.npy\", X_train)\n",
    "np.save(\"../refined_data/y_train.npy\", y_train)\n",
    "np.save(\"../refined_data/X_val.npy\", X_val)\n",
    "np.save(\"../refined_data/y_val.npy\", y_val)\n",
    "np.save(\"../refined_data/X_test.npy\", X_test)\n",
    "np.save(\"../refined_data/y_test.npy\", y_test)\n",
    "\n",
    "print(\"Data saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8650bc82",
   "metadata": {},
   "source": [
    "This serves to do a few things:\n",
    "- mention the source \n",
    "- standardize a 48x48 size\n",
    "- group them into 64 batches\n",
    "- convert images to grayscale\n",
    "- divide images categorically\n",
    "- Specify which subset is used, validation or categorical"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
